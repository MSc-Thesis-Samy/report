@inproceedings{na,
  title={First Steps Towards a Runtime Analysis of Neuroevolution},
  author={Paul Fischer and Larsen, {Emil Lundt} and Carsten Witt},
  year={2023},
  pages={"61--72"},
  booktitle={Proceedings of the 17th ACM/SIGEVO Conference on Foundations of Genetic Algorithms"},
  publisher={Association for Computing Machinery"}
}

@inproceedings{snowballing,
author = {Wohlin, Claes},
title = {Guidelines for snowballing in systematic literature studies and a replication in software engineering},
year = {2014},
publisher = {Association for Computing Machinery},
booktitle = {Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {38},
numpages = {10},
series = {EASE '14}
}

@article{systematic_review,
title = {Guidelines for conducting systematic mapping studies in software engineering: An update},
journal = {Information and Software Technology},
volume = {64},
pages = {1-18},
year = {2015},
author = {Kai Petersen and Sairam Vakkalanka and Ludwik Kuzniarz},
}

@ARTICLE{neat,
  author={Stanley, Kenneth O. and Miikkulainen, Risto},
  journal={Evolutionary Computation},
  title={Evolving Neural Networks through Augmenting Topologies},
  year={2002},
  volume={10},
  number={2},
  pages={99-127},
}

@book{proben,
  author       = {Prechelt, Lutz},
  year         = {1994},
  title        = {PROBEN 1 - a set of benchmarks and benchmarking rules for neural network training algorithms},
  language     = {english},
  note         = {Karlsruhe 1994. (Technical report. Fakultät für Informatik, Universität Karlsruhe. 1994,21.)}
}

@INPROCEEDINGS{pole_balancing,
  author={Wieland, A.P.},
  booktitle={IJCNN-91-Seattle International Joint Conference on Neural Networks},
  title={Evolving neural network controllers for unstable systems},
  year={1991},
  volume={ii},
  number={},
  pages={667-673 vol.2},
}

@misc{sgd,
      title={Optimization for deep learning: theory and algorithms},
      author={Ruoyu Sun},
      year={2019},
      eprint={1912.08957},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{adam,
      title={Adam: A Method for Stochastic Optimization},
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@INPROCEEDINGS{speech,
  author={Deng, Li and Hinton, Geoffrey and Kingsbury, Brian},
  booktitle={2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
  title={New types of deep neural network learning for speech recognition and related applications: an overview},
  year={2013},
  volume={},
  number={},
  pages={8599-8603},
  keywords={Neural networks;Speech recognition;Acoustics;Hidden Markov models;Speech;Training;Optimization;deep neural network;convolutional neural network;recurrent neural network;optimization;spectrogram features;multitask;multilingual;speech recognition;music processing},
  doi={10.1109/ICASSP.2013.6639344}}


@inproceedings{attention,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{cnn,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@INPROCEEDINGS{layers,
  author={Uzair, Muhammad and Jamil, Noreen},
  booktitle={2020 IEEE 23rd International Multitopic Conference (INMIC)},
  title={Effects of Hidden Layers on the Efficiency of Neural networks},
  year={2020},
  volume={},
  number={},
  pages={1-6},
  keywords={Neural network;Hidden layers;Neurons;Accuracy;Time complexity},
  doi={10.1109/INMIC50486.2020.9318195}}

@misc{openai_es,
      title={Evolution Strategies as a Scalable Alternative to Reinforcement Learning},
      author={Tim Salimans and Jonathan Ho and Xi Chen and Szymon Sidor and Ilya Sutskever},
      year={2017},
      eprint={1703.03864},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{ea_applications,
  title={Evolutionary algorithms and their applications to engineering problems},
  author={Adam Słowik and Halina Kwasnicka},
  journal={Neural Computing and Applications},
  year={2020},
  volume={32},
  pages={12363 - 12379},
  url={https://api.semanticscholar.org/CorpusID:212732659}
}

@ARTICLE{neuroevolution_trends,
  author={Galván, Edgar and Mooney, Peter},
  journal={IEEE Transactions on Artificial Intelligence},
  title={Neuroevolution in Deep Neural Networks: Current Trends and Future Challenges},
  year={2021},
  volume={2},
  number={6},
  pages={476-493},
  keywords={Computer architecture;Deep learning;Training data;Neural networks;Machine learning algorithms;Optimization;Feature extraction;Neuroscience;Evolutionary algorithms;Deep learning (DL);deep neural networks (DNNs);evolutionary algorithms (EAs);machine learning;neuroevolution},
  doi={10.1109/TAI.2021.3067574}}

@article{nas_survey,
   title={A Survey on Evolutionary Neural Architecture Search},
   volume={34},
   ISSN={2162-2388},
   url={http://dx.doi.org/10.1109/TNNLS.2021.3100554},
   DOI={10.1109/tnnls.2021.3100554},
   number={2},
   journal={IEEE Transactions on Neural Networks and Learning Systems},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Liu, Yuqiao and Sun, Yanan and Xue, Bing and Zhang, Mengjie and Yen, Gary G. and Tan, Kay Chen},
   year={2023},
   month=feb, pages={550–570} }

@article{neuroevolution_rl,
title = {Neuroevolution strategies for episodic reinforcement learning},
journal = {Journal of Algorithms},
volume = {64},
number = {4},
pages = {152-168},
year = {2009},
note = {Special Issue: Reinforcement Learning},
issn = {0196-6774},
doi = {https://doi.org/10.1016/j.jalgor.2009.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0196677409000364},
author = {Verena Heidrich-Meisner and Christian Igel},
keywords = {Reinforcement learning, Evolution strategy, Covariance matrix adaptation, Partially observable Markov decision process, Direct policy search},
abstract = {Because of their convincing performance, there is a growing interest in using evolutionary algorithms for reinforcement learning. We propose learning of neural network policies by the covariance matrix adaptation evolution strategy (CMA-ES), a randomized variable-metric search algorithm for continuous optimization. We argue that this approach, which we refer to as CMA Neuroevolution Strategy (CMA-NeuroES), is ideally suited for reinforcement learning, in particular because it is based on ranking policies (and therefore robust against noise), efficiently detects correlations between parameters, and infers a search direction from scalar reinforcement signals. We evaluate the CMA-NeuroES on five different (Markovian and non-Markovian) variants of the common pole balancing problem. The results are compared to those described in a recent study covering several RL algorithms, and the CMA-NeuroES shows the overall best performance.}
}
@article{neuroevolution_survey,
author = {Stanley, Kenneth and Clune, Jeff and Lehman, Joel and Miikkulainen, Risto},
year = {2019},
month = {01},
pages = {},
title = {Designing neural networks through neuroevolution},
volume = {1},
journal = {Nature Machine Intelligence},
doi = {10.1038/s42256-018-0006-z}
}

@misc{gym,
      title={OpenAI Gym},
      author={Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
      year={2016},
      eprint={1606.01540},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@ARTICLE{cmaes,
  author={Hansen, Nikolaus and Ostermeier, Andreas},
  journal={Evolutionary Computation},
  title={Completely Derandomized Self-Adaptation in Evolution Strategies},
  year={2001},
  volume={9},
  number={2},
  pages={159-195},
  keywords={Evolution strategy;self-adaptation;strategy parameter control;step size control;de-randomization;derandomized self-adaptation;covariance matrix adaptation;evolution path;cumulation;cumulative path length control},
  doi={10.1162/106365601750190398}}
