\chapter{Introduction}

Neuroevolution is a subfield of artificial intelligence which consists in the evolution of artificial neural networks (ANNs).
ANNs are traditionally trained using gradient-based methods, such as stochastic gradient descent or its extensions (e.g Adam) \cite{sgd,adam}.
Over the years, these methods have been successfully applied to a variety of problems, such as image classification, speech recognition and natural language processing \cite{attention,cnn,speech}.
Such problems generally allow for supervised learning, where ANNs are trained on a dataset of input-output pairs.
However, there is a class of problems for which supervised learning is not applicable, and where instead of input-output pairs, only a measure of performance is available, which results
in such approaches not being applicable.
In addition, the performance of ANNs is also heavily impacted by their architectures \cite{layers}. However, the design of ANNs architecture is a complex and time-consuming task, which is
topically done by hand, based on experience, trial-and-error and prior knowledge of the problem at hand.

Neuroevolution, on the other hand, as a more general approach, can, in particular, be applied to other classes of problems, as well as to the design of ANNs architectures.
This method is based on the use of evolutionary algorithms, which are inspired by the process of natural selection. These algorithms maintain a population of individuals,
which are mutated and recombined to evolve towards optimal solutions. They have shown success for black-box problems, and have successfully been applied to a wide range
of engineering problems over the years \cite{openai_es,ea_applications}.

The field of neuroevolution has been researched for over 40 years, hence many different algorithms, benchmarks and applications have been proposed.
As a matter of fact, neuroevolution encapsulates algorithms with different goals, such as the optimization of the weights of a fixed topology, the evolution of a
network topology alongside the use of gradient-based methods for optimizing weights, the evolution of both the topology and weights, as well as the evolution
of hyperparameters or reinforcement learning policies \cite{neuroevolution_trends,neuroevolution_survey,nas_survey,neuroevolution_rl}.
However, in this thesis, we are interested in approaches relying entirely on neuroevolution, without the need for gradient-based methods, for evolving neural network
parameters, using evolved or fixed topologies. In addition to these approaches, Various benchmark problems covering different problem classes sch as classification,
continuous control or game planning, have also have been proposed and applied in the applied and theoretical literature for evaluating and comparing the different algorithms \cite{gym}.

The focus of this thesis is the development of a framework that implements a selection of neuroevolution algorithms.
The framework is used to evaluate and compare the algorithms on a selection of benchmarks.
It is implemented in Rust \footnote{\url{https://www.rust-lang.org/}}, and allows for the visualization of the problems and the solution process through a graphical user interface.
The algorithms can be run and tested through a command line interface, in order to allow for the execution of experiments and the collection of results,
based on passed-in parameters and configurations.

The algorithms and benchmarks implemented in the framework were selected from the state-of-the art in the theoretical and applied research in the field of neuroevolution,
with a particular focus on recent algorithms and benchmarks proposed in $2023$ and $2024$ in the neuroevolution theory literature.
In addition to these proposals, NeuroEvolution of Augmenting Topologies (NEAT) \cite{neat}, a classic algorithm in the field, and the use of evolution strategies with
Covariance Matrix Adaptation Evolution Strategy (CMA-ES) for the evolution of weights \cite{cmaes}, achieving state-of-the-art results, were also considered.
Regarding the benchmarks, in addition to the simple two-dimensional binary classification benchmarks from the considered theory literature \cite{na,bna} and the toy \textit{XOR}
problem \cite{neat}, the classic double pole balancing problem \cite{pole_balancing} and the \textit{Proben1 Cancer1} \cite{proben} classification problem were also implemented.

\subsection{Overview}

The ordering of chapters in this report follows the chronological order of work performed for this project.
The report is structured as follows:

\Cref{chap:background} provides an overview of the background and context of the project. It introduces the notion of artificial neural networks, the main problem classes,
evolutionary algorithms and neuroevolution.

\Cref{chap:review} gives the results of a literature review conducted on neuroevolution algorithms and benchmarks. It presents the state-of-the-art in the field,
with a particular focus on recent algorithms and benchmarks proposed in the neuroevolution theory literature from 2023 and 2024.
Moreover, it also presents the selection of algorithms and benchmarks that were considered in this thesis and implemented in the framework, motivating the choices and
discussing these selected algorithms and benchmarks in further detail.

\Cref{chap:framework} describes the process of designing and implementing the framework for running neuroevolution algorithms on benchmark problems,
gathering statistics on these runs, and allowing for a visualization of the problems and solution process through a graphical user interface. This is done by first
specifying the goals and requirements of the framework, followed by a walk-through of the main design and implementation points of the framework.

\Cref{chap:experiments} lays out the results collected from running experiments using the implemented framework.
Results are presented for the selection of algorithms and benchmarks, and are discussed and compared in detail. Based on these results, a collection of
observations, hypothesises and guidelines for algorithms and parameters selection, given the problem at hand, are presented.

Finally, \Cref{chap:future_work} identifies the limitations of the project and discusses the potential lines of future work for refining and expanding on the results
previously presented. The main work and contributions of this project are finally summed up in \Cref{chap:conclusion} which concludes the report and reflects on its
results.
