\chapter{Literature Review}
\label{chap:review}

This chapter covers the first task of this thesis project, which is the review of the literature on neuroevolution algorithms and benchmarks.
The first goal of this review is to identify the state of the art algorithms and benchmarks which were proposed in the neuroevolution literature, with a particular
focus on the recent theory literature from 2023 and 2024. Following this, a selection of algorithms and benchmarks from the ones which were identified is made.
This selection consists in the algorithms and benchmarks which are presented in detail in this section and which are implemented in the framework.

\section{Methodology}

Given the large amount of literature on this well-established field, the review was conducted in a systematic manner, following the guidelines of \cite{...}.
Indeed, using a rigid methodology is important in order to ensure that the review is impartial and precise.

\subsection{Research Questions}

The research goals are summarized in the following research questions:

\begin{itemize}
    \item \textbf{RQ1:} What are the state of the art neuroevolution algorithms?
    \item \textbf{RQ2:} What are the different kinds of neuroevolution algorithms?
    \item \textbf{RQ3:} Which benchmarks are used to evaluate neuroevolution algorithms?
    \item \textbf{RQ4:} What are the key characteristics of these benchmarks?
\end{itemize}

\textbf{RQ1} and \textbf{RQ3} are concerned with the identification of the state of the art algorithms and benchmarks, while \textbf{RQ2} and \textbf{RQ4} are concerned
with the selection process.

\subsection{Search Strategy}

The search for papers was performed using Google Scholar and the DTU Findit database, which should provide an accurate representation fo the research that has been
conducted on the topic. The keywords used for designing the search queries are:

\begin{quote}
    "Neuroevolution", "Neural Networks", "Evolution Algorithm", "Evaluation"
\end{quote}

\subsection{Study Selection}

Following the queries on the databases, the results are then filtered based on the title, abstract and full-text reading (in this order). An iteration of forward
and backward snowballing were then conducted to include other studies which were missed in the initial search.

The following inclusion criteria were applied to the abstracts:

\begin{itemize}
    \item \textbf{IC1:} The paper is published after 2002.
    \item \textbf{IC2:} It is clear that the work is proposing a new noeuroevolution algorithm or performing an evaluation of existing algorithms.
    \item \textbf{IC3:} The considered algorithm(s) rely solely on evolutionary algorithms
\end{itemize}

And the following exclusion criteria were used:

\begin{itemize}
    \item \textbf{EC1:} The paper is not available in English.
    \item \textbf{EC2:} The full=text of the paper is not accessible
    \item \textbf{EC3:} The study is a duplicate of a previously included study.
\end{itemize}

The cut-off date of 2002 is motivated by the release year of the \cite{..} paper, proposing the NEAT algorithm, which is the most well-known neuroevolution algorithm
is still the subject of many studies today.

\section{Neuroevolution algorithms}

A variety of neuroevolution algorithms have been proposed in the literature.
These algorithms can be classified into different categories based on their main characteristics.
The following three main distinctions have been identified during the review:

\begin{itemize}
    \item \textbf{Conventional neuroevolution algorithms vs. TWEANNs} Conventional neuroevolution algorithms are those which only evolve the connection weights,
        considering a fixed topology, while TWEANNs (Topology and Weight Evolving Artificial Neural Networks) are those which also evolve the topology of the
        neural network.
    \item \textbf{The category of the evolutionary algorithm} such as genetic algorithms, evolutionary strategies, genetic programming, etc.
    \item \textbf{The encoding strategy} This refers to the way the neural network is encoded as a genotype, which is then evolved by the algorithm.
        The most common encoding strategies are direct encoding, indirect encoding and generative encoding.
\end{itemize}

% TODO algorithm table with categories

\subsection{(1 + 1) NA}

The (1 + 1) NA algorithm and its variants were introduced in \cite{na}.
In this work, the authors consider a simple neuroevolution setting where these algorithms are used to optimize the weights and activation function of
a simple artificial neural network.

\subsubsection{The artificial neural network topology}

Artificial neurons with $D$ inputs and a binary threshold activation function are considered.
These neurons have $D$ parameters, the input weights $w_1, \ldots, w_D$ and the threshold $t$.
Let $x = (x_1, \ldots, x_D) \in \mathds{R}^D$ be the input of the neuron. The neuron outputs $1$ if $\sum_{i=1}^D w_i x_i \geq t$ and $0$
otherwise.
This can be interpreted geometrically as the neuron outputting $1$ if the input vector $x$ is above or on the hyperplane with normal vector
$w = (w_1, \ldots, w_D)$ and bias $t$.
j
Furthermore, an alternative representation of the decision hyperplane can be used by considering spherical coordinates.
The normal vector to the decision hyperplane is described by by $D - 1$ angles and the bias, where the bias corresponds to the distance from the origin
measured in the opposite direction of that of the normal vector.
As a matter of fact, for $D = 2$, the normal vector can be represented by its cartesian coordinates $(x_1, x_2)$ or by its polar coordinates
$(r, \theta)$, where $r$ is the distance from the origin and $\theta$ is the angle with the $x_1$ axis. Similarly, for $D = 3$, the normal vector can
be represented by its cartesian coordinates $(x_1, x_2, x_3)$ or by its spherical coordinates $(r, \theta, \phi)$, where $r$ is the distance from the
origin, $\theta$ is the angle with the $x_1$ axis and $\phi$ is the angle with the $x_3$ axis.
It is easy to convert between these two representations. In addition, the spherical representation uses one less parameter than the cartesian
representation, and hence, allows for the reduction of the number of inputs to the neurons to $D - 1$.

% TODO coordinates figure

The ANNs which are considered in the study contain two layers, a hidden layer with $N > 1$ neurons and an output layer with a single neuron.
Each of the hidden neurons are connected to the $D$ inputs and output a binary value. The output neuron is connected to the $N$ hidden neurons and
computes the Boolean OR function of their outputs.
This architecture is motivated by the problems which are considered in the study, described in \Cref{subsec:na-problems}.
Geometrically, these ANNs output the union of a number of $N$-dimensional hyperplanes.

% TODO ANN figure

\subsubsection{The (1 + 1) NA algorithm}

Let's consider an ANN with $N$ neurons in the hidden layer and $D$ inputs, with parameters
$(\phi_{1,1}, \dots, \phi_{1,D-1}, b_1, \dots, \phi_{N,1}, \dots, \phi_{N,D-1}, b_N$.
In the paper \cite{na}, the search space $[0 , \dots, n]^{N D}$ is considered, where $r$ is the resolution of the continuous $[0, 1]$ domain.
This discretiisation allows for the values $\{0, 1/r, 2/r, \dots, 1\}$. Setting the parameters of ANNs is tipically a continous optimization problem,
but rigurous runtime analysis is much less developed for continous optimization than for discrete optimization, which motivates this choice.
Let $f : \{0 , \dots, r\}^{N D} \to [0, 1]$ be the fitness function which measures the performance of the ANN and is to be maximized.

The (1 + 1) NA algorithm is given in \Cref{alg:na}.
It maintains a single individual and mutates all angles and biases independently, based on a global search operator using the harmonic distribution
$\text{Harm}(r)$ on $\{1, \dots, r\}$: For $l \sim \text{Harm}(r)$,

\[
    Prob(l = i) = \frac{1}{H_r} \text{ for } i = 1, \dots, r, \text{ where } H_r = \sum_{i=1}^r \frac{1}{i}.
\]

\begin{algorithm}
\caption{(1 + 1) NA}
\label{alg:na}
\begin{algorithmic}
    \State $t \gets 0$
    \State Select $x_0$ uniformly at random from $\{0, \ldots, r\}^{DN}$.
    \While{termination criterion not met}
        \State Let $y = (\varphi_{1,1}, \ldots, \varphi_{1,D-1}, b_1, \ldots, \varphi_{N,1}, \ldots, \varphi_{N,N-1}, b_N) \gets x_t;$
        \ForAll{$i \in \{1, \ldots, N\}$}
            \State Mutate $\varphi_i$ and $b_i$ with probability $\frac{1}{DN}$, independently of each other and other indices;
            \State Mutation chooses $\sigma \in \{-1, 1\}$ uniformly at random and $l \sym \text{Harm}(r)$ and adds $\sigma l$ to the selected component, the
            result is then taken modulo $r$ for angles and modulo $r + 1$ for biases.
            \For {$i \in \{1, \ldots, N\}$}
                \State Set bias $2b_i / r - 1$ for neuron $i$.
                \For {$j \in \{1, \ldots, D\}$}
                    \State Set the $j$-th polar angle to $2\pi \varphi_{i,j} / r$ for neuron $i$.
                \EndFor
            \EndFor
            \State Evaluate $f(y)$
            \If{$f(y) \geq f(x_t)$}
                \State $x_{t+1} \gets y$
            \Else
                \State $x_{t+1} \gets x_t$
            \EndIf
        \EndFor
        \State $t \gets t + 1$
    \EndWhile
\end{algorithmic}
\end{algorithm}

\subsection{Bias-Invariant (1+1) NA (BNA)}

In \cite{bna}, the authors extend upon the analysis in \cite{na} by considering more realistic ANN settings, presenting the Bias-Invariant (1+1) NA (BNA) algorithm.
The considered ANNs uses Rectified-Linear-Unit (ReLU) activation functions, commonly used in real-world ANNs.
This allows for the construction of bended hyperplanes, resulting in solutions to the problems described in \Cref{subsec:na-problems} which are invariant
to the bias.

\subsubsection{The artificial neural network topology}

The considered ANNs contain three layers, in which each of the neurons uses a ReLU activation function i.e they output $\max(0, \sum_{i=1}^k w_i x_i)$ for
$k$ inputs from the previous layer.
The weights between the first and second layer and between the second and third layer are fixed. The topology for $D = 2$ in shown in \Cref{fig:bna-ann}.
The use of ReLU activation functions results in piecewise linear output. Hence, as described in \Cref{fig:bna-ann} for the case $D = 2$, these networks compute a
V-shaped area of positive classification. Such topologies are considered as a single neuron, refered to as a \textbf{V-neuron}, and which can be part of a
standard ANN topology.

Therefore, these V-neurons can be described by $D + 1$ parameters:

\begin{itemize}
    \item The bias $b$
    \item The $D - 1$ angles $\varphi_1, \ldots, \varphi_{D-1}$.
    \item The bend angle $\theta$.
\end{itemize}

The area of positive classification is a (multi-dimensional) cone, all points positively classified correspond to points forming an angle smaller than the bend
angle $\theta$ with the normal vector to the hyperplane given by the bias $b$ and the $D -1$ angles $\varphi_1, \ldots, \varphi_{D-1}$.

% TODO ANN figure
% TODO v-neuron classification figure

\subsubsection{The Bias-Invariant (1+1) NA algorithm}

The BNA algorithm is given in \Cref{alg:bna}.
It is mostly the same as the (1+1) NA algorithm, with the difference that the bend angles are also mutated.

\begin{algorithm}
    \caption{Bias-Invariant (1 + 1) NA (BNA)}
\label{alg:bna}
\begin{algorithmic}
    \State $t \gets 0$
    \State Select $x_0$ uniformly at random from $\{0, \ldots, r\}^{DN}$.
    \While{termination criterion not met}
        \State Let $y = (\theta_1, \varphi_{1,1}, \ldots, \varphi_{1,D-1}, b_1, \ldots, \theta_N, \varphi_{N,1}, \ldots, \varphi_{N,N-1}, b_N) \gets x_t;$
        \ForAll{$i \in \{1, \ldots, N\}$}
            \State Mutate $\varphi_i$ and $b_i$ with probability $\frac{1}{(D+1) N}$, independently of each other and other indices;
            \State Mutation chooses $\sigma \in \{-1, 1\}$ uniformly at random and $l \sym \text{Harm}(r)$ and adds $\sigma l$ to the selected component, the
            result is then taken modulo $r$ for angles and modulo $r + 1$ for biases.
            \For {$i \in \{1, \ldots, N\}$}
                \State Set bias $2b_i / r - 1$ for neuron $i$.
                \State Set bend angle $\pi \theta_i / r$ for neuron $i$.
                \For {$j \in \{1, \ldots, D\}$}
                    \State Set the $j$-th polar angle to $2\pi \varphi_{i,j} / r$ for neuron $i$.
                \EndFor
            \EndFor
            \State Evaluate $f(y)$
            \If{$f(y) \geq f(x_t)$}
                \State $x_{t+1} \gets y$
            \Else
                \State $x_{t+1} \gets x_t$
            \EndIf
        \EndFor
        \State $t \gets t + 1$
    \EndWhile
\end{algorithmic}
\end{algorithm}

\subsection{The CMA-ES Evolutionary Strategy}

CMA-ES, short for \textit{Covariance Matrix Adaptation Evolution Strategy}, is a kind of evolution strategy (ES). An ES is an optimization technique based on evolution, and
belonging to the class of evolutionary algorithms (EA).
This kind of blax-box optimization algorithms aim at optimizing a function $f : \mathds{R}^n \to \mathds{R}$, for which the analytic form is not known,
but for which evaluations of the function are possible. As it ts the case for CMA-ES, These algorithms are typically stochastic and are used for the optimization of
non-linear or non-convex continuous optimization problems.

ES algorithms maintain a population of candidate solutions. These candidate solutions are sampled from a multivariate normal distribution. Parameters of the distribution
are updated at each generation based on the performance of the candidate solutions. As a matter of fact, a simple greedy ES algorithm could consist in updating the
mean of the distribution, and using a fixed standard deviation. The mean is updated to the best solution after the evaluation of the fitness of each of the candidate
solutions. The next generation is then sampled around this mean. However, this kind of simple greedy algorithms is particularly prone to getting stuck at local optima because
of the lack of exploration.

In order to allow for more exploration, rather than exclusively relying on the single best solution, genetic algorithm maintain a proportion of the best solutions from
the current generation, and generate the next one trough recombinations and mutations. However, this approach is also prone to getting stuck at local optima, as in
practice, candidates solutions end up converging to a local optimum.

CMA-ES addresses these issues and allows for the adaption of the search space when needed, reducing it when the confidence in current solutions is high, for fine-tuning, or
increasing it when the confidence is low, in order to allow for more exploration. This is done by adapting the covariance matrix of the multivariate normal distribution,
which stores pairwise dependencies between the parameters for the sample distribution. This makes CMA-ES a powerful and widely used optimization algorithm. The main drawback
of this algorithm is its computational cost, induced by the use of the covariance matrix, which makes it less suitable for high-dimensional problems.

...

% TODO CMA-ES figure

\section{Neuroevolution benchmarks}

\subsection{Unit hypersphere sphere classification problems}

%TODO add figures

These problems, which can be thought of as a kind of \textsc{onemax} for the (1 + 1) NA algorithm, were introduced in \cite{na}.
These problems consist in the binary classification of points in the $D$-dimensional unit hypersphere.

\paragraph{Half}
The \textsc{half} problem consists of all points with non-negative $x_D$ coordinate on the unit hypersphere:

\[
    \textsc{half} = \{x \in \mathds{R}^D, \lVert x \rVert_2 = 1 \text{ and } \varphi_{D-1} \in [0, \pi]\}.
\]

\paragraph{Quarter}
The \textsc{quarter} problem consists of all points with non-negative $x_{D-1}$ and $x_D$ coordinate on the unit hypersphere:

\[
    \textsc{quarter} = \{x \in \mathds{R}^D, \lVert x \rVert_2 = 1 \text{ and } \varphi_{D-1} \in [0, \pi / 2]\}.
\]

\paragraph{TwoQuarters}
The \textsc{twoquarters} problem consists of all points with either both negative or non-negative $x_{D-1}$ and $x_D$ coordinate on the unit hypersphere:

\[
    \textsc{twoquarters} = \{x \in \mathds{R}^D, \lVert x \rVert_2 = 1 \text{ and } \varphi_{D-1} \in [0, \pi / 2] \cup [\pi, 3\pi / 2]\}.
\]

\paragraph{LocalOpt}
The \textsc{localopt} problem consists of all points with polar angle $\varphi_{D-1}$ between 0 and 60, 120 and 180, 240 and 300 degrees:

\[
    \textsc{localopt} = \{x \in \mathds{R}^D, \lVert x \rVert_2 = 1 \text{ and } \varphi_{D-1} \in [0, \pi / 3] \cup [2\pi / 3, \pi] \cup [4\pi / 3, 5\pi / 3]\}.
\]

% Square and cube
