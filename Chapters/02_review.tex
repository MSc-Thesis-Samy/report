\chapter{Literature Review}
\label{chap:review}

This chapter covers the first task of this thesis project, which is the review of the literature on neuroevolution algorithms and benchmarks.
The first goal of this review is to identify the state of the art algorithms and benchmarks which were proposed in the neuroevolution literature, with a particular
focus on the recent theory literature from 2023 and 2024. Following this, a selection of algorithms and benchmarks from the ones which were identified is made.
This selection consists in the algorithms and benchmarks which are presented in detail in this section and which are implemented in the framework.

\section{Methodology}

Given the large amount of literature on this well-established field, the review was conducted in a systematic manner, following the guidelines of \cite{...}.
Indeed, using a rigid methodology is important in order to ensure that the review is impartial and precise.

\subsection{Research Questions}

The research goals are summarized in the following research questions:

\begin{itemize}
    \item \textbf{RQ1:} What are the state of the art neuroevolution algorithms?
    \item \textbf{RQ2:} What are the different kinds of neuroevolution algorithms?
    \item \textbf{RQ3:} Which benchmarks are used to evaluate neuroevolution algorithms?
    \item \textbf{RQ4:} What are the key characteristics of these benchmarks?
\end{itemize}

\textbf{RQ1} and \textbf{RQ3} are concerned with the identification of the state of the art algorithms and benchmarks, while \textbf{RQ2} and \textbf{RQ4} are concerned
with the selection process.

\subsection{Search Strategy}

The search for papers was performed using Google Scholar and the DTU Findit database, which should provide an accurate representation fo the research that has been
conducted on the topic. The keywords used for designing the search queries are:

\begin{quote}
    "Neuroevolution", "Neural Networks", "Evolution Algorithm", "Evaluation"
\end{quote}

\subsection{Study Selection}

Following the queries on the databases, the results are then filtered based on the title, abstract and full-text reading (in this order). An iteration of forward
and backward snowballing were then conducted to include other studies which were missed in the initial search.

The following inclusion criteria were applied to the abstracts:

\begin{itemize}
    \item \textbf{IC1:} The paper is published after 2002.
    \item \textbf{IC2:} It is clear that the work is proposing a new noeuroevolution algorithm or performing an evaluation of existing algorithms.
    \item \textbf{IC3:} The considered algorithm(s) rely solely on evolutionary algorithms
\end{itemize}

And the following exclusion criteria were used:

\begin{itemize}
    \item \textbf{EC1:} The paper is not available in English.
    \item \textbf{EC2:} The full=text of the paper is not accessible
    \item \textbf{EC3:} The study is a duplicate of a previously included study.
\end{itemize}

The cut-off date of 2002 is motivated by the release year of the \cite{..} paper, proposing the NEAT algorithm, which is the most well-known neuroevolution algorithm
is still the subject of many studies today.

\section{Neuroevolution algorithms}

A variety of neuroevolution algorithms have been proposed in the literature.
These algorithms can be classified into different categories based on their main characteristics.
The following three main distinctions have been identified during the review:

\begin{itemize}
    \item \textbf{Conventional neuroevolution algorithms vs. TWEANNs} Conventional neuroevolution algorithms are those which only evolve the connection weights,
        considering a fixed topology, while TWEANNs (Topology and Weight Evolving Artificial Neural Networks) are those which also evolve the topology of the
        neural network.
    \item \textbf{The category of the evolutionary algorithm} such as genetic algorithms, evolutionary strategies, genetic programming, etc.
    \item \textbf{The encoding strategy} This refers to the way the neural network is encoded as a genotype, which is then evolved by the algorithm.
        The most common encoding strategies are direct encoding, indirect encoding and generative encoding.
\end{itemize}

% TODO algorithm table with categories

\subsection{Algorithms selection}

The following algorithms were selected for the implementation in the framework:

\begin{itemize}
    \item The (1 + 1) NA algorithm and its variants
    \item The Bias-Invariant (1+1) NA (BNA) algorithm
    \item The CMA-ES Evolutionary Strategy
    \item The NEAT algorithm
\end{itemize}

Given the duration of the project, the choice was made to limit the number of algorithms to four, in order to allow for a thorough implementation and evaluation of
each of them, thus various criteria were used for the selection of the algorithm, to allow for a good coverage of the different categories of algorithms and
interesting comparisons between them.

Therfore, the (1 + 1) NA and bias-invariant (1+1) NA algorithms were selected as the two theory paper proposals this thesis is particularly interested in.
The CMA-ES algorithm, which is the representative of the evolutionary strategies category was selected because of its popularity in the modern neuroevolution literature
and applications, and because of its status as a state-of-the-art algorithm for continuous optimization problems.
Finally, the NEAT algorithm, the representative of the TWEANN category, was selected because of its status as the most well-known neuroevolution algorithm, making
it a subject of most comparison studies in the literature.

\subsection{(1 + 1) NA}

The (1 + 1) NA algorithm and its variants were introduced in \cite{na}.
In this work, the authors consider a simple neuroevolution setting where these algorithms are used to optimize the weights and activation function of
a simple artificial neural network.

\subsubsection{The artificial neural network topology}

Artificial neurons with $D$ inputs and a binary threshold activation function are considered.
These neurons have $D$ parameters, the input weights $w_1, \ldots, w_D$ and the threshold $t$.
Let $x = (x_1, \ldots, x_D) \in \mathds{R}^D$ be the input of the neuron. The neuron outputs $1$ if $\sum_{i=1}^D w_i x_i \geq t$ and $0$
otherwise.
This can be interpreted geometrically as the neuron outputting $1$ if the input vector $x$ is above or on the hyperplane with normal vector
$w = (w_1, \ldots, w_D)$ and bias $t$.
j
Furthermore, an alternative representation of the decision hyperplane can be used by considering spherical coordinates.
The normal vector to the decision hyperplane is described by by $D - 1$ angles and the bias, where the bias corresponds to the distance from the origin
measured in the opposite direction of that of the normal vector.
As a matter of fact, for $D = 2$, the normal vector can be represented by its cartesian coordinates $(x_1, x_2)$ or by its polar coordinates
$(r, \theta)$, where $r$ is the distance from the origin and $\theta$ is the angle with the $x_1$ axis. Similarly, for $D = 3$, the normal vector can
be represented by its cartesian coordinates $(x_1, x_2, x_3)$ or by its spherical coordinates $(r, \theta, \phi)$, where $r$ is the distance from the
origin, $\theta$ is the angle with the $x_1$ axis and $\phi$ is the angle with the $x_3$ axis.
It is easy to convert between these two representations. In addition, the spherical representation uses one less parameter than the cartesian
representation, and hence, allows for the reduction of the number of inputs to the neurons to $D - 1$.

% TODO coordinates figure

The ANNs which are considered in the study contain two layers, a hidden layer with $N > 1$ neurons and an output layer with a single neuron.
Each of the hidden neurons are connected to the $D$ inputs and output a binary value. The output neuron is connected to the $N$ hidden neurons and
computes the Boolean OR function of their outputs.
This architecture is motivated by the problems which are considered in the study, described in \Cref{subsec:na-problems}.
Geometrically, these ANNs output the union of a number of $N$-dimensional hyperplanes.

% TODO ANN figure

\subsubsection{The (1 + 1) NA algorithm}

Let's consider an ANN with $N$ neurons in the hidden layer and $D$ inputs, with parameters
$(\phi_{1,1}, \dots, \phi_{1,D-1}, b_1, \dots, \phi_{N,1}, \dots, \phi_{N,D-1}, b_N$.
In the paper \cite{na}, the search space $[0 , \dots, n]^{N D}$ is considered, where $r$ is the resolution of the continuous $[0, 1]$ domain.
This discretiisation allows for the values $\{0, 1/r, 2/r, \dots, 1\}$. Setting the parameters of ANNs is tipically a continous optimization problem,
but rigurous runtime analysis is much less developed for continous optimization than for discrete optimization, which motivates this choice.
Let $f : \{0 , \dots, r\}^{N D} \to [0, 1]$ be the fitness function which measures the performance of the ANN and is to be maximized.

The (1 + 1) NA algorithm is given in \Cref{alg:na}.
It maintains a single individual and mutates all angles and biases independently, based on a global search operator using the harmonic distribution
$\text{Harm}(r)$ on $\{1, \dots, r\}$: For $l \sim \text{Harm}(r)$,

\[
    Prob(l = i) = \frac{1}{H_r} \text{ for } i = 1, \dots, r, \text{ where } H_r = \sum_{i=1}^r \frac{1}{i}.
\]

\begin{algorithm}
\caption{(1 + 1) NA}
\label{alg:na}
\begin{algorithmic}
    \State $t \gets 0$
    \State Select $x_0$ uniformly at random from $\{0, \ldots, r\}^{DN}$.
    \While{termination criterion not met}
        \State Let $y = (\varphi_{1,1}, \ldots, \varphi_{1,D-1}, b_1, \ldots, \varphi_{N,1}, \ldots, \varphi_{N,N-1}, b_N) \gets x_t;$
        \ForAll{$i \in \{1, \ldots, N\}$}
            \State Mutate $\varphi_i$ and $b_i$ with probability $\frac{1}{DN}$, independently of each other and other indices;
            \State Mutation chooses $\sigma \in \{-1, 1\}$ uniformly at random and $l \sym \text{Harm}(r)$ and adds $\sigma l$ to the selected component, the
            result is then taken modulo $r$ for angles and modulo $r + 1$ for biases.
            \For {$i \in \{1, \ldots, N\}$}
                \State Set bias $2b_i / r - 1$ for neuron $i$.
                \For {$j \in \{1, \ldots, D\}$}
                    \State Set the $j$-th polar angle to $2\pi \varphi_{i,j} / r$ for neuron $i$.
                \EndFor
            \EndFor
            \State Evaluate $f(y)$
            \If{$f(y) \geq f(x_t)$}
                \State $x_{t+1} \gets y$
            \Else
                \State $x_{t+1} \gets x_t$
            \EndIf
        \EndFor
        \State $t \gets t + 1$
    \EndWhile
\end{algorithmic}
\end{algorithm}

\subsection{Bias-Invariant (1+1) NA (BNA)}

In \cite{bna}, the authors extend upon the analysis in \cite{na} by considering more realistic ANN settings, presenting the Bias-Invariant (1+1) NA (BNA) algorithm.
The considered ANNs uses Rectified-Linear-Unit (ReLU) activation functions, commonly used in real-world ANNs.
This allows for the construction of bended hyperplanes, resulting in solutions to the problems described in \Cref{subsec:na-problems} which are invariant
to the bias.

\subsubsection{The artificial neural network topology}

The considered ANNs contain three layers, in which each of the neurons uses a ReLU activation function i.e they output $\max(0, \sum_{i=1}^k w_i x_i)$ for
$k$ inputs from the previous layer.
The weights between the first and second layer and between the second and third layer are fixed. The topology for $D = 2$ in shown in \Cref{fig:bna-ann}.
The use of ReLU activation functions results in piecewise linear output. Hence, as described in \Cref{fig:bna-ann} for the case $D = 2$, these networks compute a
V-shaped area of positive classification. Such topologies are considered as a single neuron, refered to as a \textbf{V-neuron}, and which can be part of a
standard ANN topology.

Therefore, these V-neurons can be described by $D + 1$ parameters:

\begin{itemize}
    \item The bias $b$
    \item The $D - 1$ angles $\varphi_1, \ldots, \varphi_{D-1}$.
    \item The bend angle $\theta$.
\end{itemize}

The area of positive classification is a (multi-dimensional) cone, all points positively classified correspond to points forming an angle smaller than the bend
angle $\theta$ with the normal vector to the hyperplane given by the bias $b$ and the $D -1$ angles $\varphi_1, \ldots, \varphi_{D-1}$.

% TODO ANN figure
% TODO v-neuron classification figure

\subsubsection{The Bias-Invariant (1+1) NA algorithm}

The BNA algorithm is given in \Cref{alg:bna}.
It is mostly the same as the (1+1) NA algorithm, with the difference that the bend angles are also mutated.

\begin{algorithm}
    \caption{Bias-Invariant (1 + 1) NA (BNA)}
\label{alg:bna}
\begin{algorithmic}
    \State $t \gets 0$
    \State Select $x_0$ uniformly at random from $\{0, \ldots, r\}^{DN}$.
    \While{termination criterion not met}
        \State Let $y = (\theta_1, \varphi_{1,1}, \ldots, \varphi_{1,D-1}, b_1, \ldots, \theta_N, \varphi_{N,1}, \ldots, \varphi_{N,N-1}, b_N) \gets x_t;$
        \ForAll{$i \in \{1, \ldots, N\}$}
            \State Mutate $\varphi_i$ and $b_i$ with probability $\frac{1}{(D+1) N}$, independently of each other and other indices;
            \State Mutation chooses $\sigma \in \{-1, 1\}$ uniformly at random and $l \sym \text{Harm}(r)$ and adds $\sigma l$ to the selected component, the
            result is then taken modulo $r$ for angles and modulo $r + 1$ for biases.
            \For {$i \in \{1, \ldots, N\}$}
                \State Set bias $2b_i / r - 1$ for neuron $i$.
                \State Set bend angle $\pi \theta_i / r$ for neuron $i$.
                \For {$j \in \{1, \ldots, D\}$}
                    \State Set the $j$-th polar angle to $2\pi \varphi_{i,j} / r$ for neuron $i$.
                \EndFor
            \EndFor
            \State Evaluate $f(y)$
            \If{$f(y) \geq f(x_t)$}
                \State $x_{t+1} \gets y$
            \Else
                \State $x_{t+1} \gets x_t$
            \EndIf
        \EndFor
        \State $t \gets t + 1$
    \EndWhile
\end{algorithmic}
\end{algorithm}

\subsection{The CMA-ES Evolutionary Strategy}

CMA-ES, short for \textit{Covariance Matrix Adaptation Evolution Strategy}, is a kind of evolution strategy (ES). An ES is an optimization technique based on evolution, and
belonging to the class of evolutionary algorithms (EA).
This kind of blax-box optimization algorithms aim at optimizing a function $f : \mathds{R}^n \to \mathds{R}$, for which the analytic form is not known,
but for which evaluations of the function are possible. As it ts the case for CMA-ES, These algorithms are typically stochastic and are used for the optimization of
non-linear or non-convex continuous optimization problems.

ES algorithms maintain a population of candidate solutions. These candidate solutions are sampled from a multivariate normal distribution. Parameters of the distribution
are updated at each generation based on the performance of the candidate solutions. As a matter of fact, a simple greedy ES algorithm could consist in updating the
mean of the distribution, and using a fixed standard deviation. The mean is updated to the best solution after the evaluation of the fitness of each of the candidate
solutions. The next generation is then sampled around this mean. However, this kind of simple greedy algorithms is particularly prone to getting stuck at local optima because
of the lack of exploration.

In order to allow for more exploration, rather than exclusively relying on the single best solution, genetic algorithm maintain a proportion of the best solutions from
the current generation, and generate the next one trough recombinations and mutations. However, this approach is also prone to getting stuck at local optima, as in
practice, candidates solutions end up converging to a local optimum.

CMA-ES addresses these issues and allows for the adaption of the search space when needed, reducing it when the confidence in current solutions is high, for fine-tuning, or
increasing it when the confidence is low, in order to allow for more exploration. This is done by adapting the covariance matrix of the multivariate normal distribution,
which stores pairwise dependencies between the parameters for the sample distribution. This makes CMA-ES a powerful and widely used optimization algorithm. The main drawback
of this algorithm is its computational cost, induced by the use of the covariance matrix, which makes it less suitable for high-dimensional problems.

...

% TODO CMA-ES figure

CMA-ES can be used for the evolution of fixed-topology neural networks, by considering the weights of the connections as the parameters of the optimization problem,
and converting between a vector representation of the network, for the optimization input, and the standard graph representation, for the evaluation.

\subsection{Neuroevolution of Augmenting Topologies (NEAT)}

The NEAT algorithm was introduced in \cite{neat}. It is a TWANN (Topology and Weight Evolving Artificial Neural Network) algorithm, which evolves, simultaneously,  both
the topology and weights of neural networks. The main idea behind this algorithm is to start from a minimal topology, incrementally adding new neurons and connections to,
the networks, which allows for the evolution of complex neural networks while keeping the computational cost low and justifying each new addition to the network topology.
The following sections describe the main components of the algorithm.

\subsubsection{Genetic Encoding}

NEAT uses a direct encoding of the neural networks. The goal of the encoding strategy is to allow crossover among different network topologies.
Each genome contains two sets of genes, which specify nodes and connections in the network:

\begin{itemize}
    \item \textbf{Node genes} Each node gene contains an identifier and layer (input, hidden, output or bias, which is an input that is always set to $1.0$.
    \item \textbf{Connection genes} Each connection gene specifies an input node identifier, an output node identifier, a weight, whether the connection is enabled or
        disabled, and an innovation number.
\end{itemize}

% TODO NEAT encoding figure

Where node identifiers are shared between the individuals in the population, the enabled flag specifies whether or not the connection is expressed in the phenotype (i.e
the network) and the innovation number is used to track the historical origin of the gene.

\subsubsection{Mutations}

NEAT uses two types of mutations: weight mutations and structural mutations. Weight mutations are used to perturb the weights of the connections in the network,while
structural mutations are used to modify the topology of the network. There are two types of structural mutations:

\begin{itemize}
    \item \textbf{Add connection} This mutation adds a new connection between two unconnected nodes in the network. The connection is assigned a random weight.
    \item \textbf{Add node} This mutation adds a new node in the network, splitting an existing connection into two. The old connection is disabled and two new
        connections are added to the new node. The connection leading into the new node is assigned a weight of 1, while the connection leading out from the new node is
        assigned the weight of the old connection. This allows for the minimization of the initial effort of the mutation, as the activation of the output layer
        node remains the same and the weights of the new connections can be optimized in future generations.
\end{itemize}

Because of these two types of mutations, inserting new nodes and connection genes, genomes can only grow larger over time, resulting in the evolution of increasingly
complex networks.

\subsubsection{Crossover}

One of the challenges of evolving neural networks is the crossover operator, because of the different topologies of the networks. NEAT addresses this issue by making
use of the innovation numbers in connection genes, which allows for the tracking of the historical origin of each gene. This allows for the matching of genes between
individuals. Genes are assigned increasing innovation numbers as they appear in the population and innovation numbers are inherited. Hence, the matching of genes is done
by comparing the innovation numbers. Thus, the crossover operator consists in inheriting matching genes from one parent at random, and adding the remaining disjoint
and excess genes from the fittest parent. This strategy is particularly cost-effective as it requires no topological analysis of the networks.

% TODO NEAT crossover figure

\subsubsection{Speciation}

An issue with the current strategy is that the population is unable to protect topological innovation, because of smaller topologies optimizing faster and the
addition of new connections usually resulting in an initial drop in fitness. To address this issue, NEAT uses speciation, which groups individuals into species based
on their genetic similarity. This strategy allows for the protection of topological innovation by having individuals compete within their specie, rather than the entire population.
In addition, as it is the case with the crossover operator, historical matching allows for an efficient solution.

The similarity between two individuals is computed as a weighted sum of the number of excess genes, the number of disjoint genes and the average weight difference
of matching genes. At each generation, individuals are sequentially assigned to a specie based on the similarity with the representative of the specie, which is
a randomly selected individual from the previous generation which was part of the specie, and a similarity threshold. If no specie is found, a new specie is created.

...

% TODO offsprings split and adjusted fitness
% TODO NEAT similarity formula

\section{Neuroevolution benchmarks}

\subsection{Unit hypersphere sphere classification problems}
\label{subsection:sphere_classification}

%TODO add figures

These problems, which can be thought of as a kind of \textsc{onemax} for the (1 + 1) NA algorithm, were introduced in \cite{na}.
These problems consist in the binary classification of points in the $D$-dimensional unit hypersphere.

\paragraph{Half}
The \textsc{half} problem consists of all points with non-negative $x_D$ coordinate on the unit hypersphere:

\[
    \textsc{half} = \{x \in \mathds{R}^D, \lVert x \rVert_2 = 1 \text{ and } \varphi_{D-1} \in [0, \pi]\}.
\]

\paragraph{Quarter}
The \textsc{quarter} problem consists of all points with non-negative $x_{D-1}$ and $x_D$ coordinate on the unit hypersphere:

\[
    \textsc{quarter} = \{x \in \mathds{R}^D, \lVert x \rVert_2 = 1 \text{ and } \varphi_{D-1} \in [0, \pi / 2]\}.
\]

\paragraph{TwoQuarters}
The \textsc{twoquarters} problem consists of all points with either both negative or non-negative $x_{D-1}$ and $x_D$ coordinate on the unit hypersphere:

\[
    \textsc{twoquarters} = \{x \in \mathds{R}^D, \lVert x \rVert_2 = 1 \text{ and } \varphi_{D-1} \in [0, \pi / 2] \cup [\pi, 3\pi / 2]\}.
\]

\paragraph{LocalOpt}
The \textsc{localopt} problem consists of all points with polar angle $\varphi_{D-1}$ between 0 and 60, 120 and 180, 240 and 300 degrees:

\[
    \textsc{localopt} = \{x \in \mathds{R}^D, \lVert x \rVert_2 = 1 \text{ and } \varphi_{D-1} \in [0, \pi / 3] \cup [2\pi / 3, \pi] \cup [4\pi / 3, 5\pi / 3]\}.
\]

% Square and cube

\subsection{XOR}

This classic benchmark problem is a binary classification problem, which consists in the classification of the four points $(0, 0)$, $(0, 1)$, $(1, 0)$ and $(1, 1)$, according to the XOR function.
The points $(0, 0)$ and $(1, 1)$ are of class $0$, while the points $(0, 1)$ and $(1, 0)$ are of class $1$.
The popularity of this simple problem comes from its non-linear nature, which makes it impossible to solve with a single-layer perceptro.

\subsection{Dataset Classification Problems}

Classification using datasets is a classical use-case for neural networks. It consists in training a network on labeled data and using it to
predict the label of unseen data. Hence, the hypersphere classification problems, presented in \Cref{subsection:sphere_classification}, from the
theory studies, differ from this kind of task, by having algorithms trained and tested on the same data.

Although these problems are not common use-cases for neuroevolution because of the use of labeled data,
they are particularly interesting for this study, by allowing to show how neuroevolution can be applied to these common tasks, testing
the algorithms on larger state spaces, and potentially observing whether common behaviors which occur when training ANNs using gradient-based methods,
such as over-fitting or under-fitting, also apply to neuroevolution.

The proben1 benchmark, presented in \cite{...}, introduces various standard benchmark datasets, including the \texit{cancer} dataset, which
contains $699$ entries, consisting in cell descriptors gathered by microscopic for tumors being benign or malignant.
Each dataset entry contains $9$ input features, and a binary output,

The algorithms are evolved using the first $90\%$ of the data, and are tested on the remaining $10\%$.

\subsection{Pole Balancing}

The pole balancing problem, introduced in \cite{...}, is a classical benchmark in control theory, reinforcement learning and neuroevolution literature.
It consists in controlling a cart with one degree of freedom, which moves along a one-dimensional track, by applying a horizontal force to it, in order to balance a pole attached to it.
Some of the reasons for the popularity of this benchmark problem are its simplicity, its relevance to real-world control problems and its unstable and non-linear dynamics.

% TODO pole balancing figure

The difficulty of the problem can be adjusted by changing the number of poles. Indeed, if the poles have different lengths, they will react differently to the forces applied to the cart.
As the single pole variant has become too easy for current techniques, we consider the widely used case of double pole balancing, where two poles are attached to the cart.

The state of the system is described by the cart position $x$, the cart velocity $\dot{x}$, the pole angles $\theta_1$ and $\theta_2$ and the angular velocities $\dot{\theta}_1$ and $\dot{\theta}_2$.
This task is Markovian, as the state contains all the information needed to determine the future evolution of the system.
A more challenging variant of the problem consists in removing the velocity informations from the state, which requires the use of recurrent connections, which were not considered
in this project.

The dynamics of the system are described by the following equations:

... % TODO equations

The equations for motion are integrated using the Euler method:

... % TODO equations

The fitness function is defined as the sum of the time steps during which the poles are balanced and the cart is within the allowed bounds, over $1000$ time steps.
A pole is considered balanced if its angle is within $30$ degrees of the vertical position.
The evaluated algorithms outputs are mapped to the magnitude of the force $F \in [-10, 10]$N to be applied to the car at each time step.
